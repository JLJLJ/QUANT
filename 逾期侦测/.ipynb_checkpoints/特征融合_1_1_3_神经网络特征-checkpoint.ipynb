{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "from functools import wraps\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.externals import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import timedelta\n",
    "from io import StringIO\n",
    "# from sklearn.externals import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas.tseries.offsets import Day,Hour,Minute\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns',None) \n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "#我的多核函数，可以提高训练速度，考虑到总行复现环境不确定性，就没有用\n",
    "def applyParallel(dfGrouped, func):\n",
    "    ret = Parallel(n_jobs=multiprocessing.cpu_count()-6)(delayed(func)(name,group) for name, group in dfGrouped)\n",
    "    return pd.concat(ret)\n",
    "\n",
    "#调参类定义，传入多个参数组成的一个字典，返回一个迭代器，感觉比sklearn中的调参函数好用，个人习惯吧\n",
    "class params_iter:\n",
    "    def getPlans(self,lis,jude=True):\n",
    "        if jude: \n",
    "            lis = [[[i] for i in lis[0]]] + lis[1:]\n",
    "        if len(lis) > 2:\n",
    "            for i in lis[0]:\n",
    "                for j in lis[1]:\n",
    "                    self.getPlans([[i + [j]]] + lis[2:], False)\n",
    "        elif len(lis) == 2:\n",
    "            for i in lis[0]:\n",
    "                for j in lis[1]:\n",
    "                    self.param_list.append(i + [j])\n",
    "                \n",
    "    def __init__(self,params):\n",
    "        self.params=params\n",
    "        self.cur_index=0\n",
    "        self.param_list=[]\n",
    "        val=list(params.values())\n",
    "        keys=list(params.keys())\n",
    "        self.getPlans(val)\n",
    "        self.df=pd.DataFrame(param_list,columns=keys)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        x = self.df.iloc[self.cur_index,:]\n",
    "        self.cur_index += 1\n",
    "        return x.to_dict()\n",
    "def to_hdf(dataset,name):\n",
    "    dataset_train=dataset[pd.isna(dataset['target'])==False].copy()\n",
    "    dataset_test=dataset[pd.isna(dataset['target'])].copy()\n",
    "    dataset_train.to_hdf('dataset/'+name+'.h5', key='TRAIN')\n",
    "    dataset_test.to_hdf('dataset/'+name+'.h5', key='PREDICT')\n",
    "def read_hdf(name):\n",
    "    dataset_train = pd.read_hdf('dataset/'+name+'.h5', key='TRAIN')\n",
    "    dataset_test = pd.read_hdf('dataset/'+name+'.h5', key='PREDICT')\n",
    "    return pd.concat([dataset_train,dataset_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('dataset/LOAN_TRAIN_SET.csv',header=0,index_col ='cust_no')\n",
    "dataset_test = pd.read_csv('dataset/LOAN_PREDICT_SET_03.csv',header=0,index_col ='cust_no')\n",
    "dataset_train.to_hdf('dataset/1_原数据转存.h5', key='TRAIN')\n",
    "dataset_test.to_hdf('dataset/1_原数据转存.h5', key='PREDICT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_0=['cus_age','cus_mbank_lcnt','cus_active_ind','pass_date','interval_mon_count',\n",
    "        'interval_date_1stc','interval_date_1stc12','cus_hisloan_cnt','crcd_mavg_balind'\n",
    "       ]\n",
    "fill_avg=['cus_region_move_ind','cus_reloan_cap_ind','cus_asset_bal','crcd_max_quota','crcd_lmon_due_amount',\n",
    "          'crcd_due_amount','crcd_mavg_balance'\n",
    "         ]\n",
    "fill_f1=['crcd_points',\n",
    "         'a_mmax_tranbal','a_mavg_tranbal','b_mmax_tranbal','b_mavg_tranbal','c_mmax_tranbal','c_mavg_tranbal',\n",
    "         'd_mmax_tranbal','d_mavg_tranbal','e_mmax_tranbal','e_mavg_tranbal','f_mmax_tranbal','f_mavg_tranbal',\n",
    "         'g_mmax_tranbal','g_mavg_tranbal','h_mmax_tranbal','h_mavg_tranbal','i_mmax_tranbal','i_mavg_tranbal',\n",
    "         'j_mmax_tranbal','j_mavg_tranbal','k_mmax_tranbal','k_mavg_tranbal','m_mmax_tranbal','m_mavg_tranbal',\n",
    "         'n_mavg_trancount','n_mavg_tranbal'\n",
    "        ]\n",
    "fill_f1_div=['a_mdivision_tranbal',\n",
    "             'b_mdivision_tranbal',\n",
    "             'c_mdivision_tranbal',\n",
    "             'd_mdivision_tranbal',\n",
    "             'e_mdivision_tranbal',\n",
    "             'f_mdivision_tranbal',\n",
    "             'g_mdivision_tranbal',\n",
    "             'h_mdivision_tranbal',\n",
    "             'i_mdivision_tranbal',\n",
    "             'j_mdivision_tranbal',\n",
    "             'k_mdivision_tranbal',\n",
    "             'm_mdivision_tranbal',\n",
    "             'n_mdivision_tranbal',\n",
    "             \n",
    "             'a_div_cus_asset_bal',\n",
    "             'b_div_cus_asset_bal',\n",
    "             'c_div_cus_asset_bal',\n",
    "             'd_div_cus_asset_bal',\n",
    "             'e_div_cus_asset_bal',\n",
    "             'f_div_cus_asset_bal',\n",
    "             'g_div_cus_asset_bal',\n",
    "             'h_div_cus_asset_bal',\n",
    "             'i_div_cus_asset_bal',\n",
    "             'j_div_cus_asset_bal',\n",
    "             'k_div_cus_asset_bal',\n",
    "             'm_div_cus_asset_bal',\n",
    "             'n_div_cus_asset_bal',\n",
    "             \n",
    "            'pass_date1',\n",
    "            'pass_date1',\n",
    "            'pass_date2',\n",
    "            'pass_date',\n",
    "            'interval_mon_count1',\n",
    "            'interval_mon_count2',\n",
    "\n",
    "            'new12',\n",
    "            'new13',\n",
    "            'new14',\n",
    "            'new15',\n",
    "            'new16',\n",
    "            'new17',\n",
    "            'new18',\n",
    "            'new1',\n",
    "            'new2',\n",
    "            'new3',\n",
    "            'new4',\n",
    "            'new5',\n",
    "            'new6',\n",
    "            'new7',\n",
    "            'new8',\n",
    "            'new9',\n",
    "            'new10',\n",
    "            'new11',\n",
    "            'crcd1',\n",
    "            'crcd2',\n",
    "            'crcd3',\n",
    "            'crcd4',\n",
    "            'crcd5',\n",
    "            'interval_date1',\n",
    "            'cus_asset_bal1',\n",
    "            'cus_asset_bal2',\n",
    "            'cus_marr_stat1']\n",
    "\n",
    "\n",
    "confinuous_feature=fill_0+fill_avg+fill_f1+fill_f1_div\n",
    "cago_feature=['crcd_is_overdue','cus_sex','crcd_is_pc','crcd_is_sup','cus_type','crcd_is_gec','crcd_bachange_cnt','cus_intvtime_trans',\n",
    "              'cus_edu','cus_marr_stat','cus_occu','cus_oact_pla','cus_os_dist','crcd_is_gc','crcd_bill_mcnt']\n",
    "\n",
    "print(len(cago_feature),cago_feature)\n",
    "print(len(confinuous_feature),confinuous_feature)\n",
    "feature=cago_feature+confinuous_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset=read_hdf('1_原数据转存') \n",
    "\n",
    "dataset['index']=range(len(dataset))\n",
    "dataset['a_mdivision_tranbal']=dataset['a_mmax_tranbal']/dataset['a_mavg_tranbal']\n",
    "dataset['b_mdivision_tranbal']=dataset['b_mmax_tranbal']/dataset['b_mavg_tranbal']\n",
    "dataset['c_mdivision_tranbal']=dataset['c_mmax_tranbal']/dataset['c_mavg_tranbal']\n",
    "dataset['d_mdivision_tranbal']=dataset['d_mmax_tranbal']/dataset['d_mavg_tranbal']\n",
    "dataset['e_mdivision_tranbal']=dataset['e_mmax_tranbal']/dataset['e_mavg_tranbal']\n",
    "dataset['f_mdivision_tranbal']=dataset['f_mmax_tranbal']/dataset['f_mavg_tranbal']\n",
    "dataset['g_mdivision_tranbal']=dataset['g_mmax_tranbal']/dataset['g_mavg_tranbal']\n",
    "dataset['h_mdivision_tranbal']=dataset['h_mmax_tranbal']/dataset['h_mavg_tranbal']\n",
    "dataset['i_mdivision_tranbal']=dataset['i_mmax_tranbal']/dataset['i_mavg_tranbal']\n",
    "dataset['j_mdivision_tranbal']=dataset['j_mmax_tranbal']/dataset['j_mavg_tranbal']\n",
    "dataset['k_mdivision_tranbal']=dataset['k_mmax_tranbal']/dataset['k_mavg_tranbal']\n",
    "dataset['m_mdivision_tranbal']=dataset['m_mmax_tranbal']/dataset['m_mavg_tranbal']\n",
    "dataset['n_mdivision_tranbal']=dataset['n_mavg_trancount']/dataset['n_mavg_tranbal']\n",
    "\n",
    "dataset['a_div_cus_asset_bal']=dataset['a_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['b_div_cus_asset_bal']=dataset['b_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['c_div_cus_asset_bal']=dataset['c_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['d_div_cus_asset_bal']=dataset['d_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['e_div_cus_asset_bal']=dataset['e_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['f_div_cus_asset_bal']=dataset['f_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['g_div_cus_asset_bal']=dataset['g_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['h_div_cus_asset_bal']=dataset['h_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['i_div_cus_asset_bal']=dataset['i_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['j_div_cus_asset_bal']=dataset['j_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['k_div_cus_asset_bal']=dataset['k_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['m_div_cus_asset_bal']=dataset['m_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "dataset['n_div_cus_asset_bal']=dataset['n_mavg_tranbal']/dataset['cus_asset_bal']\n",
    "\n",
    "dataset['pass_date1']=pd.to_datetime(dataset.pass_date.values,unit='s')#转换时间戳\n",
    "dataset['pass_date1']=(datetime.now()-dataset['pass_date1']).apply(lambda x:x.days)#求距离到现在的天数\n",
    "dataset['pass_date2']=(dataset['pass_date']-dataset['pass_date'].min())/3600/24\n",
    "dataset['pass_date']=dataset['pass_date']/3600/24\n",
    "dataset['interval_mon_count1']=dataset['interval_mon_count']*30-dataset['pass_date1']\n",
    "dataset['interval_mon_count2']=dataset['interval_mon_count']*30/dataset['pass_date1']\n",
    "dataset['new12']=dataset['a_mavg_tranbal']+dataset['b_mavg_tranbal']+dataset['d_mavg_tranbal']+dataset['e_mavg_tranbal']+dataset['g_mavg_tranbal']+dataset['h_mavg_tranbal']+dataset['i_mavg_tranbal']\n",
    "dataset['new13']=dataset['a_mmax_tranbal']+dataset['b_mmax_tranbal']+dataset['d_mmax_tranbal']+dataset['e_mmax_tranbal']+dataset['g_mmax_tranbal']+dataset['h_mmax_tranbal']+dataset['i_mmax_tranbal']\n",
    "dataset['new14']=dataset['new12']/dataset['new13']\n",
    "dataset['new15']=dataset['new13']/dataset['new12']\n",
    "dataset['new16']=dataset['a_mavg_tranbal']+dataset['b_mavg_tranbal']+dataset['c_mavg_tranbal']+dataset['d_mavg_tranbal']+dataset['e_mavg_tranbal']+dataset['f_mavg_tranbal']+dataset['g_mavg_tranbal']+dataset['h_mavg_tranbal']+dataset['i_mavg_tranbal']+dataset['j_mavg_tranbal']+dataset['k_mavg_tranbal']\n",
    "dataset['new17']=dataset['a_mmax_tranbal']+dataset['b_mmax_tranbal']+dataset['c_mmax_tranbal']+dataset['d_mmax_tranbal']+dataset['e_mmax_tranbal']+dataset['f_mmax_tranbal']+dataset['g_mmax_tranbal']+dataset['h_mmax_tranbal']+dataset['i_mmax_tranbal']+dataset['j_mmax_tranbal']+dataset['k_mmax_tranbal']\n",
    "dataset['new18']=dataset['new16']/dataset['new17']\n",
    "dataset['new1']=dataset['a_mmax_tranbal']/dataset['a_mavg_tranbal']\n",
    "dataset['new2']=dataset['b_mmax_tranbal']/dataset['b_mavg_tranbal']\n",
    "dataset['new3']=dataset['c_mmax_tranbal']/dataset['c_mavg_tranbal']\n",
    "dataset['new4']=dataset['d_mmax_tranbal']/dataset['d_mavg_tranbal']\n",
    "dataset['new5']=dataset['e_mmax_tranbal']/dataset['e_mavg_tranbal']\n",
    "dataset['new6']=dataset['f_mmax_tranbal']/dataset['f_mavg_tranbal']\n",
    "dataset['new7']=dataset['g_mmax_tranbal']/dataset['g_mavg_tranbal']\n",
    "dataset['new8']=dataset['h_mmax_tranbal']/dataset['h_mavg_tranbal']\n",
    "dataset['new9']=dataset['i_mmax_tranbal']/dataset['i_mavg_tranbal']\n",
    "dataset['new10']=dataset['j_mmax_tranbal']/dataset['j_mavg_tranbal']\n",
    "dataset['new11']=dataset['k_mmax_tranbal']/dataset['k_mavg_tranbal']\n",
    "dataset['crcd1']=dataset['crcd_due_amount']/dataset['crcd_mavg_balance'] #信用卡当月欠款除以月均账单\n",
    "dataset['crcd2']=dataset['crcd_lmon_due_amount']/dataset['crcd_due_amount']#信用卡上月账单除以当月账单\n",
    "dataset['crcd3']=dataset['crcd_max_quota']/dataset['crcd_due_amount']#信用卡额度除以当月账单\n",
    "dataset['crcd4']=dataset['crcd_max_quota']/dataset['crcd_lmon_due_amount']#信用卡额度除以上月账单\n",
    "dataset['crcd5']=dataset['crcd_due_amount']/dataset['crcd_lmon_due_amount']#信用卡当月欠款除以当月账单\n",
    "dataset['interval_date1']=dataset['interval_date_1stc12']-dataset['interval_date_1stc']\n",
    "dataset['cus_asset_bal1']=dataset['cus_asset_bal']/dataset['crcd_due_amount']\n",
    "dataset['cus_asset_bal2']=dataset['cus_asset_bal']/dataset['new12']\n",
    "dataset['cus_marr_stat1']=dataset['cus_marr_stat']+dataset['crcd_is_sup']\n",
    "\n",
    "to_hdf(dataset,'1_1_特征衍生')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=read_hdf('1_1_特征衍生') \n",
    "# columns=dataset.columns\n",
    "\n",
    "dataset[fill_0]=dataset[fill_0].fillna(0)\n",
    "dataset[fill_f1]=dataset[fill_f1].fillna(-1)\n",
    "\n",
    "for c in fill_avg:\n",
    "    dataset[c]=dataset[c].fillna(dataset[c].mean())\n",
    "\n",
    "dataset[cago_feature]=dataset[cago_feature].fillna(-999)\n",
    "for c in cago_feature:\n",
    "    dataset[c]=LabelEncoder().fit_transform(dataset[c])\n",
    "    \n",
    "dataset[fill_f1_div]=dataset[fill_f1_div].fillna(-1)\n",
    "\n",
    "to_hdf(dataset,'1_1_1_空值填充')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=read_hdf('1_1_特征衍生') \n",
    "# columns=dataset.columns\n",
    "\n",
    "dataset[fill_0]=dataset[fill_0].fillna(0)\n",
    "dataset[fill_f1]=dataset[fill_f1].fillna(-1)\n",
    "\n",
    "for c in fill_avg:\n",
    "    dataset[c]=dataset[c].fillna(dataset[c].mean())\n",
    "\n",
    "dataset[cago_feature]=dataset[cago_feature].fillna(-999)\n",
    "for c in cago_feature:\n",
    "    dataset[c]=LabelEncoder().fit_transform(dataset[c])\n",
    "    \n",
    "# dataset[fill_f1_div]=dataset[fill_f1_div].fillna(-1)\n",
    "\n",
    "to_hdf(dataset,'1_1_2_空值填充')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=read_hdf('1_1_1_空值填充') \n",
    "\n",
    "#98上分位数去异常值\n",
    "columns98=['cus_mbank_lcnt', 'interval_mon_count', 'interval_date_1stc', 'cus_hisloan_cnt', 'crcd_mavg_balind', 'cus_reloan_cap_ind',\n",
    "         'cus_asset_bal', 'crcd_max_quota', 'crcd_lmon_due_amount', 'crcd_due_amount', 'crcd_mavg_balance', 'a_mmax_tranbal',\n",
    "           'a_mavg_tranbal', 'b_mmax_tranbal', 'b_mavg_tranbal', 'c_mmax_tranbal', 'c_mavg_tranbal', 'd_mmax_tranbal',\n",
    "           'd_mavg_tranbal', 'e_mmax_tranbal', 'e_mavg_tranbal', 'f_mmax_tranbal', 'f_mavg_tranbal', 'g_mmax_tranbal',\n",
    "           'g_mavg_tranbal', 'h_mmax_tranbal', 'h_mavg_tranbal', 'i_mmax_tranbal', 'i_mavg_tranbal', 'j_mmax_tranbal', \n",
    "           'j_mavg_tranbal', 'k_mmax_tranbal', 'k_mavg_tranbal', 'm_mmax_tranbal', 'm_mavg_tranbal', 'n_mavg_trancount',\n",
    "           'n_mavg_tranbal',\n",
    "           'a_mdivision_tranbal','b_mdivision_tranbal','c_mdivision_tranbal','d_mdivision_tranbal','e_mdivision_tranbal',\n",
    "           'f_mdivision_tranbal','g_mdivision_tranbal','h_mdivision_tranbal','i_mdivision_tranbal','j_mdivision_tranbal',\n",
    "           'k_mdivision_tranbal','m_mdivision_tranbal','n_mdivision_tranbal',\n",
    "           'a_div_cus_asset_bal','b_div_cus_asset_bal','c_div_cus_asset_bal','d_div_cus_asset_bal','e_div_cus_asset_bal',\n",
    "           'f_div_cus_asset_bal','g_div_cus_asset_bal','h_div_cus_asset_bal','i_div_cus_asset_bal','j_div_cus_asset_bal',\n",
    "           'k_div_cus_asset_bal','m_div_cus_asset_bal','n_div_cus_asset_bal',\n",
    "           'new12','new13','new14','new15','new16','new17','new18','new1','new2','new3','new4','new5','new6','new7','new8','new9',\n",
    "           'new10','new11','crcd1','crcd2','crcd3','crcd4','crcd5','interval_date1','cus_asset_bal1','cus_asset_bal2']\n",
    "for c in columns98:\n",
    "    s=dataset.loc[((dataset[c]!=np.inf) & (dataset[c]!=-np.inf)),c]\n",
    "    q=s.quantile(0.98)\n",
    "    dataset.loc[dataset[c]>q,c]=q\n",
    "#95上分位数去异常值\n",
    "columns95=['crcd_points']\n",
    "for c in columns95:\n",
    "    q=dataset[c].quantile(0.95)\n",
    "    dataset.loc[dataset[c]>q,c]=q\n",
    "#下分位数去异常值\n",
    "columns02=['cus_asset_bal','crcd_lmon_due_amount','crcd_due_amount','crcd_mavg_balance','n_mavg_tranbal',\n",
    "           'a_mdivision_tranbal','b_mdivision_tranbal','c_mdivision_tranbal','d_mdivision_tranbal','e_mdivision_tranbal',\n",
    "           'f_mdivision_tranbal','g_mdivision_tranbal','h_mdivision_tranbal','i_mdivision_tranbal','j_mdivision_tranbal',\n",
    "           'k_mdivision_tranbal','m_mdivision_tranbal','n_mdivision_tranbal',\n",
    "           'a_div_cus_asset_bal','b_div_cus_asset_bal','c_div_cus_asset_bal','d_div_cus_asset_bal','e_div_cus_asset_bal',\n",
    "           'f_div_cus_asset_bal','g_div_cus_asset_bal','h_div_cus_asset_bal','i_div_cus_asset_bal','j_div_cus_asset_bal',\n",
    "           'k_div_cus_asset_bal','m_div_cus_asset_bal','n_div_cus_asset_bal','crcd1','crcd2','crcd3','crcd4','crcd5',\n",
    "           'interval_date1','cus_asset_bal1','cus_asset_bal2','new14','new18'\n",
    "        ]\n",
    "for c in columns02:\n",
    "    s=dataset.loc[((dataset[c]!=np.inf) & (dataset[c]!=-np.inf)),c]\n",
    "    q=s.quantile(0.02)\n",
    "    dataset.loc[dataset[c]<q,c]=q \n",
    "dataset[confinuous_feature] = preprocessing.scale(dataset[confinuous_feature])\n",
    "to_hdf(dataset,'1_1_1_1_去异常值并归一')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dataset.columns:\n",
    "    s=dataset[dataset[c]<-9999999]\n",
    "    if len(s):\n",
    "        print(c)\n",
    "        break\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=read_hdf('1_1_1_1_去异常值并归一') \n",
    "columns=[]\n",
    "for c in cago_feature:\n",
    "    if len(dataset[c].unique())==2:\n",
    "        columns.append(c)\n",
    "        continue\n",
    "    else:\n",
    "        new_column=pd.get_dummies(dataset[c],prefix = c)\n",
    "        dataset=pd.concat([dataset,new_column],axis=1)\n",
    "        dataset=dataset.drop([c],axis=1)\n",
    "        for nc in new_column.columns:\n",
    "            columns.append(nc)\n",
    "print(columns)\n",
    "to_hdf(dataset,'1_1_1_1_1_one-hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop feature\n",
    "drop_feature=['k_mdivision_tranbal','target','index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_0=['cus_age','cus_mbank_lcnt','cus_active_ind','pass_date','interval_mon_count',\n",
    "        'interval_date_1stc','interval_date_1stc12','cus_hisloan_cnt','crcd_mavg_balind'\n",
    "       ]\n",
    "fill_avg=['cus_region_move_ind','cus_reloan_cap_ind','cus_asset_bal','crcd_max_quota','crcd_lmon_due_amount',\n",
    "          'crcd_due_amount','crcd_mavg_balance'\n",
    "         ]\n",
    "fill_f1=['crcd_points',\n",
    "         'a_mmax_tranbal','a_mavg_tranbal','b_mmax_tranbal','b_mavg_tranbal','c_mmax_tranbal','c_mavg_tranbal',\n",
    "         'd_mmax_tranbal','d_mavg_tranbal','e_mmax_tranbal','e_mavg_tranbal','f_mmax_tranbal','f_mavg_tranbal',\n",
    "         'g_mmax_tranbal','g_mavg_tranbal','h_mmax_tranbal','h_mavg_tranbal','i_mmax_tranbal','i_mavg_tranbal',\n",
    "         'j_mmax_tranbal','j_mavg_tranbal','k_mmax_tranbal','k_mavg_tranbal','m_mmax_tranbal','m_mavg_tranbal',\n",
    "         'n_mavg_trancount','n_mavg_tranbal'\n",
    "        ]\n",
    "fill_f1_div=['a_mdivision_tranbal',\n",
    "             'b_mdivision_tranbal',\n",
    "             'c_mdivision_tranbal',\n",
    "             'd_mdivision_tranbal',\n",
    "             'e_mdivision_tranbal',\n",
    "             'f_mdivision_tranbal',\n",
    "             'g_mdivision_tranbal',\n",
    "             'h_mdivision_tranbal',\n",
    "             'i_mdivision_tranbal',\n",
    "             'j_mdivision_tranbal',\n",
    "             'm_mdivision_tranbal',\n",
    "             'n_mdivision_tranbal',\n",
    "             \n",
    "             'a_div_cus_asset_bal',\n",
    "             'b_div_cus_asset_bal',\n",
    "             'c_div_cus_asset_bal',\n",
    "             'd_div_cus_asset_bal',\n",
    "             'e_div_cus_asset_bal',\n",
    "             'f_div_cus_asset_bal',\n",
    "             'g_div_cus_asset_bal',\n",
    "             'h_div_cus_asset_bal',\n",
    "             'i_div_cus_asset_bal',\n",
    "             'j_div_cus_asset_bal',\n",
    "             'k_div_cus_asset_bal',\n",
    "             'm_div_cus_asset_bal',\n",
    "             'n_div_cus_asset_bal',\n",
    "             \n",
    "            'pass_date1',\n",
    "            'pass_date1',\n",
    "            'pass_date2',\n",
    "            'pass_date',\n",
    "            'interval_mon_count1',\n",
    "            'interval_mon_count2',\n",
    "\n",
    "            'new12',\n",
    "            'new13',\n",
    "            'new14',\n",
    "            'new15',\n",
    "            'new16',\n",
    "            'new17',\n",
    "            'new18',\n",
    "            'new1',\n",
    "            'new2',\n",
    "            'new3',\n",
    "            'new4',\n",
    "            'new5',\n",
    "            'new6',\n",
    "            'new7',\n",
    "            'new8',\n",
    "            'new9',\n",
    "            'new10',\n",
    "            'new11',\n",
    "            'crcd1',\n",
    "            'crcd2',\n",
    "            'crcd3',\n",
    "            'crcd4',\n",
    "            'crcd5',\n",
    "            'interval_date1',\n",
    "            'cus_asset_bal1',\n",
    "            'cus_asset_bal2',\n",
    "            'cus_marr_stat1']\n",
    "\n",
    "\n",
    "confinuous_feature=fill_0+fill_avg+fill_f1+fill_f1_div\n",
    "cago_feature=['crcd_is_overdue','cus_sex','crcd_is_pc','crcd_is_sup','cus_type','crcd_is_gec','crcd_bachange_cnt','cus_intvtime_trans',\n",
    "              'cus_edu','cus_marr_stat','cus_occu','cus_oact_pla','cus_os_dist','crcd_is_gc','crcd_bill_mcnt']\n",
    "\n",
    "print(len(cago_feature),cago_feature)\n",
    "print(len(confinuous_feature),confinuous_feature)\n",
    "feature=cago_feature+confinuous_feature\n",
    "confinuous_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#慎用\n",
    "dataset=read_hdf('3_0_插入产品相除列_填入空值_加入index') \n",
    "for c in dataset.columns:\n",
    "     dataset[c]=pd.to_numeric(dataset[c],downcast='signed')\n",
    "for c in dataset.columns:\n",
    "    if dataset[c].dtype=='float64':\n",
    "        m=max(abs(dataset[c].max()),abs(dataset[c].min()))\n",
    "        if m<10000:\n",
    "            dataset[c]=dataset[c].astype('float32')\n",
    "to_hdf(dataset_poly_feature,'4_0_修改数据类型')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "from functools import wraps\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.externals import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import timedelta\n",
    "from io import StringIO\n",
    "# from sklearn.externals import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from random import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('display.max_columns',None) \n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "#我的多核函数，可以提高训练速度，考虑到总行复现环境不确定性，就没有用\n",
    "def applyParallel(dfGrouped, func):\n",
    "    ret = Parallel(n_jobs=multiprocessing.cpu_count()-6)(delayed(func)(name,group) for name, group in dfGrouped)\n",
    "    return pd.concat(ret)\n",
    "\n",
    "#调参类定义，传入多个参数组成的一个字典，返回一个迭代器，感觉比sklearn中的调参函数好用，个人习惯吧\n",
    "class params_iter:\n",
    "    def getPlans(self,lis,jude=True):\n",
    "        if jude: \n",
    "            lis = [[[i] for i in lis[0]]] + lis[1:]\n",
    "        if len(lis) > 2:\n",
    "            for i in lis[0]:\n",
    "                for j in lis[1]:\n",
    "                    self.getPlans([[i + [j]]] + lis[2:], False)\n",
    "        elif len(lis) == 2:\n",
    "            for i in lis[0]:\n",
    "                for j in lis[1]:\n",
    "                    self.param_list.append(i + [j])\n",
    "                \n",
    "    def __init__(self,params):\n",
    "        self.params=params\n",
    "        self.cur_index=0\n",
    "        self.param_list=[]\n",
    "        val=list(params.values())\n",
    "        keys=list(params.keys())\n",
    "        self.getPlans(val)\n",
    "        self.df=pd.DataFrame(self.param_list,columns=keys)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        if self.df.shape[0]==self.cur_index:\n",
    "            raise StopIteration\n",
    "        x = self.df.iloc[self.cur_index,:]\n",
    "        self.cur_index += 1\n",
    "        return x.to_dict()\n",
    "    \n",
    "def get_sample(dataset,target_0=0.33,target_1=0.33,seed=None):\n",
    "    dataset=dataset.copy()\n",
    "    x0=dataset[dataset['target']==0]\n",
    "    x1=dataset[dataset['target']==1]\n",
    "    x0_selected=x0.sample(frac=target_0,random_state=seed)\n",
    "    x1_selected=x1.sample(frac=target_1,random_state=seed)\n",
    "    dataset=pd.concat([x0_selected,x1_selected]).sample(frac=1,random_state=seed)\n",
    "    y_selected=dataset['target']\n",
    "    x_selected=dataset.drop(columns =['target'])\n",
    "    return x_selected,y_selected\n",
    "def cv(dataset_x,dataset_y,model,k=5, **fit_params) : \n",
    "    models=[]\n",
    "    dataset_x=dataset_x.values\n",
    "    dataset_y=dataset_y.values\n",
    "    kf = KFold(n_splits=k,random_state=0)\n",
    "    def run(train_index, test_index,model, **fit_params):\n",
    "        X_train,X_eval = dataset_x[train_index], dataset_x[test_index]\n",
    "        Y_train,Y_eval = dataset_y[train_index], dataset_y[test_index]\n",
    "\n",
    "        model=model.fit(X_train,Y_train,eval_set=(X_eval,Y_eval),eval_metric='auc',early_stopping_rounds=200, **fit_params)\n",
    "        return model,model.best_score_['valid_0']['auc']\n",
    "    \n",
    "    re=Parallel(n_jobs=3)(delayed(run)(train_index, test_index,model, **fit_params) for train_index, test_index in kf.split(dataset_x))\n",
    "    models=pd.DataFrame(re)[0].to_list()\n",
    "    avg_score=pd.DataFrame(re)[1].mean()\n",
    "    return models,avg_score\n",
    "\n",
    "def predict(X_test,models):\n",
    "    def run(model):\n",
    "        y_pr=model.predict_proba(X_test)[:,1]\n",
    "        return y_pr\n",
    "    y_pres=Parallel(n_jobs=40)(delayed(run)(model) for model in models)\n",
    "    y_pres=pd.DataFrame(np.array(y_pres).T)\n",
    "    y_pr=y_pres.mean(axis=1)\n",
    "    y_pr.index=X_test.index\n",
    "    return y_pr\n",
    "def add_log(auc,feature,models):\n",
    "    f=open('log.txt','a+')\n",
    "    s=str(auc) +'\\r\\n'+str(feature)+'\\r\\n' +str(models) +'\\r\\n'\n",
    "    f.write(s)\n",
    "    f.close()\n",
    "def get_feature():\n",
    "    drop_feature=['k_mdivision_tranbal','target','index']\n",
    "    cago_feature=['crcd_is_overdue', 'cus_sex', 'crcd_is_pc_0', 'crcd_is_pc_1', 'crcd_is_pc_2', 'crcd_is_sup_0', 'crcd_is_sup_1', 'crcd_is_sup_2', 'cus_type_0', 'cus_type_1', 'cus_type_2', 'crcd_is_gec_0', 'crcd_is_gec_1', 'crcd_is_gec_2', 'crcd_bachange_cnt_0', 'crcd_bachange_cnt_1', 'crcd_bachange_cnt_2', 'crcd_bachange_cnt_3', 'cus_intvtime_trans_0', 'cus_intvtime_trans_1', 'cus_intvtime_trans_2', 'cus_intvtime_trans_3', 'cus_intvtime_trans_4', 'cus_edu_0', 'cus_edu_1', 'cus_edu_2', 'cus_edu_3', 'cus_edu_4', 'cus_edu_5', 'cus_marr_stat_0', 'cus_marr_stat_1', 'cus_marr_stat_2', 'cus_marr_stat_3', 'cus_occu_0', 'cus_occu_1', 'cus_occu_2', 'cus_occu_3', 'cus_occu_4', 'cus_occu_5', 'cus_occu_6', 'cus_occu_7', 'cus_occu_8', 'cus_occu_9', 'cus_occu_10', 'cus_occu_11', 'cus_occu_12', 'cus_occu_13', 'cus_occu_14', 'cus_occu_15', 'cus_occu_16', 'cus_occu_17', 'cus_occu_18', 'cus_occu_19', 'cus_occu_20', 'cus_occu_21', 'cus_occu_22', 'cus_occu_23', 'cus_occu_24', 'cus_occu_25', 'cus_occu_26', 'cus_occu_27', 'cus_occu_28', 'cus_occu_29', 'cus_occu_30', 'cus_occu_31', 'cus_occu_32', 'cus_occu_33', 'cus_occu_34', 'cus_occu_35', 'cus_oact_pla_0', 'cus_oact_pla_1', 'cus_oact_pla_2', 'cus_oact_pla_3', 'cus_oact_pla_4', 'cus_oact_pla_5', 'cus_oact_pla_6', 'cus_oact_pla_7', 'cus_oact_pla_8', 'cus_oact_pla_9', 'cus_oact_pla_10', 'cus_oact_pla_11', 'cus_oact_pla_12', 'cus_oact_pla_13', 'cus_oact_pla_14', 'cus_oact_pla_15', 'cus_oact_pla_16', 'cus_oact_pla_17', 'cus_oact_pla_18', 'cus_oact_pla_19', 'cus_oact_pla_20', 'cus_oact_pla_21', 'cus_oact_pla_22', 'cus_oact_pla_23', 'cus_oact_pla_24', 'cus_oact_pla_25', 'cus_oact_pla_26', 'cus_oact_pla_27', 'cus_oact_pla_28', 'cus_oact_pla_29', 'cus_oact_pla_30', 'cus_oact_pla_31', 'cus_oact_pla_32', 'cus_oact_pla_33', 'cus_oact_pla_34', 'cus_oact_pla_35', 'cus_oact_pla_36', 'cus_oact_pla_37', 'cus_oact_pla_38', 'cus_oact_pla_39', 'cus_oact_pla_40', 'cus_oact_pla_41', 'cus_oact_pla_42', 'cus_oact_pla_43', 'cus_oact_pla_44', 'cus_oact_pla_45', 'cus_oact_pla_46', 'cus_oact_pla_47', 'cus_oact_pla_48', 'cus_oact_pla_49', 'cus_oact_pla_50', 'cus_oact_pla_51', 'cus_oact_pla_52', 'cus_oact_pla_53', 'cus_oact_pla_54', 'cus_os_dist_0', 'cus_os_dist_1', 'cus_os_dist_2', 'cus_os_dist_3', 'cus_os_dist_4', 'cus_os_dist_5', 'cus_os_dist_6', 'cus_os_dist_7', 'cus_os_dist_8', 'cus_os_dist_9', 'cus_os_dist_10', 'cus_os_dist_11', 'cus_os_dist_12', 'cus_os_dist_13', 'cus_os_dist_14', 'cus_os_dist_15', 'cus_os_dist_16', 'cus_os_dist_17', 'cus_os_dist_18', 'cus_os_dist_19', 'cus_os_dist_20', 'cus_os_dist_21', 'cus_os_dist_22', 'cus_os_dist_23', 'cus_os_dist_24', 'cus_os_dist_25', 'cus_os_dist_26', 'cus_os_dist_27', 'cus_os_dist_28', 'cus_os_dist_29', 'cus_os_dist_30', 'cus_os_dist_31', 'cus_os_dist_32', 'cus_os_dist_33', 'cus_os_dist_34', 'cus_os_dist_35', 'cus_os_dist_36', 'cus_os_dist_37', 'cus_os_dist_38', 'cus_os_dist_39', 'cus_os_dist_40', 'cus_os_dist_41', 'cus_os_dist_42', 'cus_os_dist_43', 'cus_os_dist_44', 'cus_os_dist_45', 'cus_os_dist_46', 'cus_os_dist_47', 'cus_os_dist_48', 'cus_os_dist_49', 'cus_os_dist_50', 'cus_os_dist_51', 'cus_os_dist_52', 'cus_os_dist_53', 'cus_os_dist_54', 'cus_os_dist_55', 'crcd_is_gc_0', 'crcd_is_gc_1', 'crcd_is_gc_2', 'crcd_bill_mcnt_0', 'crcd_bill_mcnt_1', 'crcd_bill_mcnt_2', 'crcd_bill_mcnt_3', 'crcd_bill_mcnt_4', 'crcd_bill_mcnt_5', 'crcd_bill_mcnt_6', 'crcd_bill_mcnt_7', 'crcd_bill_mcnt_8', 'crcd_bill_mcnt_9', 'crcd_bill_mcnt_10', 'crcd_bill_mcnt_11', 'crcd_bill_mcnt_12', 'crcd_bill_mcnt_13', 'crcd_bill_mcnt_14', 'crcd_bill_mcnt_15', 'crcd_bill_mcnt_16', 'crcd_bill_mcnt_17', 'crcd_bill_mcnt_18', 'crcd_bill_mcnt_19', 'crcd_bill_mcnt_20', 'crcd_bill_mcnt_21', 'crcd_bill_mcnt_22', 'crcd_bill_mcnt_23', 'crcd_bill_mcnt_24', 'crcd_bill_mcnt_25', 'crcd_bill_mcnt_26', 'crcd_bill_mcnt_27']\n",
    "    continue_feature=['cus_age', 'cus_mbank_lcnt', 'cus_active_ind', 'pass_date', 'interval_mon_count', 'interval_date_1stc', 'interval_date_1stc12', 'cus_hisloan_cnt', 'crcd_mavg_balind', 'cus_region_move_ind', 'cus_reloan_cap_ind', 'cus_asset_bal', 'crcd_max_quota', 'crcd_lmon_due_amount', 'crcd_due_amount', 'crcd_mavg_balance', 'crcd_points', 'a_mmax_tranbal', 'a_mavg_tranbal', 'b_mmax_tranbal', 'b_mavg_tranbal', 'c_mmax_tranbal', 'c_mavg_tranbal', 'd_mmax_tranbal', 'd_mavg_tranbal', 'e_mmax_tranbal', 'e_mavg_tranbal', 'f_mmax_tranbal', 'f_mavg_tranbal', 'g_mmax_tranbal', 'g_mavg_tranbal', 'h_mmax_tranbal', 'h_mavg_tranbal', 'i_mmax_tranbal', 'i_mavg_tranbal', 'j_mmax_tranbal', 'j_mavg_tranbal', 'k_mmax_tranbal', 'k_mavg_tranbal', 'm_mmax_tranbal', 'm_mavg_tranbal', 'n_mavg_trancount', 'n_mavg_tranbal', 'a_mdivision_tranbal', 'b_mdivision_tranbal', 'c_mdivision_tranbal', 'd_mdivision_tranbal', 'e_mdivision_tranbal', 'f_mdivision_tranbal', 'g_mdivision_tranbal', 'h_mdivision_tranbal', 'i_mdivision_tranbal', 'j_mdivision_tranbal', 'm_mdivision_tranbal', 'n_mdivision_tranbal', 'a_div_cus_asset_bal', 'b_div_cus_asset_bal', 'c_div_cus_asset_bal', 'd_div_cus_asset_bal', 'e_div_cus_asset_bal', 'f_div_cus_asset_bal', 'g_div_cus_asset_bal', 'h_div_cus_asset_bal', 'i_div_cus_asset_bal', 'j_div_cus_asset_bal', 'k_div_cus_asset_bal', 'm_div_cus_asset_bal', 'n_div_cus_asset_bal', 'pass_date1', 'pass_date2', 'pass_date', 'interval_mon_count1', 'interval_mon_count2', 'new12', 'new13', 'new14', 'new15', 'new16', 'new17', 'new18', 'new1', 'new2', 'new3', 'new4', 'new5', 'new6', 'new7', 'new8', 'new9', 'new10', 'new11', 'crcd1', 'crcd2', 'crcd3', 'crcd4', 'crcd5', 'interval_date1', 'cus_asset_bal1', 'cus_asset_bal2', 'cus_marr_stat1']\n",
    "    return cago_feature+continue_feature\n",
    "def get_sample(dataset,target_0=0.33,target_1=0.33,seed=None):\n",
    "    dataset=dataset.copy()\n",
    "    x0=dataset[dataset['target']==0]\n",
    "    x1=dataset[dataset['target']==1]\n",
    "    x0_selected=x0.sample(frac=target_0,random_state=seed)\n",
    "    x1_selected=x1.sample(frac=target_1,random_state=seed)\n",
    "    dataset=pd.concat([x0_selected,x1_selected]).sample(frac=1,random_state=seed)\n",
    "    y_selected=dataset['target']\n",
    "    x_selected=dataset.drop(columns =['target'])\n",
    "    return x_selected,y_selected\n",
    "dataset_train=pd.read_hdf('dataset/1_1_1_1_1_one-hot.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_1_1_1_one-hot.h5', key='PREDICT')\n",
    "feature=get_feature()\n",
    "feature_train=feature+['target']\n",
    "feature_test=feature\n",
    "dataset_train=dataset_train[feature_train]\n",
    "dataset_test=dataset_test[feature_test]\n",
    "dataset_train_x,dataset_train_y=get_sample(dataset_train,target_0=1,target_1=1,seed=None)\n",
    "# X_train,X_test,Y_train,Y_test=train_test_split(dataset_train_x,dataset_train_y,test_size=0.000001,random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "models=[]\n",
    "i=0\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.x_val,self.y_val = validation_data\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        global models\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            s='models/dnns/'+str(i)+'_'+str(score)[0:7]+'_'+str(epoch)+'.h5'\n",
    "            models.append((i,score,s))\n",
    "            model.save(s)\n",
    "            print(s)\n",
    "            return score\n",
    "#             if score>0.87:\n",
    "#                 model.save('model/dnn/'+s+'.h5')\n",
    "y_pres=[]\n",
    "y_pres_online=[]\n",
    "index=[]\n",
    "Xs=[]\n",
    "model=Sequential()\n",
    "def cv(dataset_x_ori,dataset_y_ori,k=5,**fit_params) : \n",
    "    global models,i,model,y_pres_online,y_pres,index,Xs\n",
    "    models=[]\n",
    "    dataset_x=dataset_x_ori.values\n",
    "    dataset_y=dataset_y_ori.values\n",
    "    kf = KFold(n_splits=k,random_state=0)\n",
    "    for train_index,test_index in kf.split(dataset_x):\n",
    "        print('!!!!!!!!!!!!!',dataset_train.shape,dataset_test.shape,)\n",
    "        \n",
    "        models=[]\n",
    "        index.append(pd.Series(test_index))\n",
    "        X_train,X_eval = dataset_x[train_index], dataset_x[test_index]\n",
    "        Y_train,Y_eval = dataset_y[train_index], dataset_y[test_index]\n",
    "#         print('1')\n",
    "#         print(dataset_x_ori.iloc[test_index[0],:].values)\n",
    "#         print(X_eval[0,:])\n",
    "#         print('2')\n",
    "#         print(dataset_x_ori.iloc[test_index[-1],:].values)\n",
    "#         print(X_eval[-1,:])\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_eval, Y_eval),interval=1)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=600, activation='relu', input_dim=311))\n",
    "        model.add(Dense(units=300,activation='relu',kernel_regularizer=regularizers.l1(0.02)))\n",
    "        model.add(Dense(units=100,activation='relu'))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "        model.fit(X_train, Y_train, batch_size=64, epochs=100, validation_data=(X_eval, Y_eval), callbacks=[RocAuc], verbose=2)\n",
    "        i=i+1\n",
    "        df=pd.DataFrame(models)\n",
    "        df=df.sort_values([1],ascending=False)\n",
    "        path=df.iat[0,2]\n",
    "        print('load',path)\n",
    "        model=load_model(path)\n",
    "        \n",
    "        y_pr=model.predict(X_eval, verbose=0)\n",
    "        y_pr=pd.DataFrame(y_pr)\n",
    "#         y_pr.index=test_index\n",
    "        y_pres.append(y_pr)\n",
    "        ###########\n",
    "        x=X_eval\n",
    "        x=pd.DataFrame(x)\n",
    "#         x.index=test_index\n",
    "        Xs.append(x)\n",
    "        ###########\n",
    "        y_pr_online=model.predict(dataset_test, verbose=0)\n",
    "        y_pr_online=pd.DataFrame(y_pr_online)\n",
    "        y_pres_online.append(y_pr_online)\n",
    "    \n",
    "    index=pd.concat(index,axis=0)\n",
    "    y_pr=pd.concat(y_pres,axis=0)\n",
    "#     y_pr.index=index\n",
    "#     y_pr=y_pr.sort_index()\n",
    "    y_pr.index=dataset_y_ori.index\n",
    "    #########\n",
    "    X=pd.concat(Xs,axis=0)\n",
    "#     X.index=index\n",
    "#     X=X.sort_index()\n",
    "    X.index=dataset_y_ori.index\n",
    "    X.columns=dataset_x_ori.columns\n",
    "    #########\n",
    "    y_pr_online=pd.concat(y_pres_online,axis=1)\n",
    "    y_pr_online=y_pr_online.mean(axis=1)\n",
    "    print(y_pr_online.shape)\n",
    "    y_pr_online.index=dataset_test.index\n",
    "    return y_pr,y_pr_online,X\n",
    "y_pr,y_pr_online,X=cv(dataset_train_x,dataset_train_y,10)\n",
    "dataset_train=pd.read_hdf('dataset/1_1_1_空值填充.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_1_空值填充.h5', key='PREDICT')\n",
    "y_pr.columns=['dnn_target']\n",
    "y_pr_online=pd.DataFrame(y_pr_online,columns=['dnn_target'])\n",
    "dataset_train=pd.concat([dataset_train,y_pr],axis=1,sort=False)\n",
    "dataset_test=pd.concat([dataset_test,y_pr_online],axis=1,sort=False)\n",
    "dataset_train.to_hdf('dataset/1_1_1_2_dnn_target.h5', key='TRAIN')\n",
    "dataset_test.to_hdf('dataset/1_1_1_2_dnn_target.h5', key='PREDICT')\n",
    "\n",
    "dataset_train=pd.read_hdf('dataset/1_1_特征衍生.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_特征衍生.h5', key='PREDICT')\n",
    "y_pr.columns=['dnn_target']\n",
    "y_pr_online=pd.DataFrame(y_pr_online,columns=['dnn_target'])\n",
    "dataset_train=pd.concat([dataset_train,y_pr],axis=1,sort=False)\n",
    "dataset_test=pd.concat([dataset_test,y_pr_online],axis=1,sort=False)\n",
    "dataset_train.to_hdf('dataset/1_1_3_dnn_target.h5', key='TRAIN')\n",
    "dataset_test.to_hdf('dataset/1_1_3_dnn_target.h5', key='PREDICT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_train=pd.read_hdf('dataset/1_1_1_空值填充.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_1_空值填充.h5', key='PREDICT')\n",
    "feature=['crcd_is_overdue', 'cus_sex', 'crcd_is_pc', 'crcd_is_sup', 'cus_type', 'crcd_is_gec', 'crcd_bachange_cnt', 'cus_intvtime_trans',\n",
    "         'cus_edu', 'cus_marr_stat', 'cus_occu', 'cus_oact_pla', 'cus_os_dist', 'crcd_is_gc', 'crcd_bill_mcnt',\n",
    "                 \n",
    "        'cus_age', 'cus_mbank_lcnt', 'cus_active_ind', 'pass_date', 'interval_mon_count', 'interval_date_1stc', 'interval_date_1stc12', 'cus_hisloan_cnt', 'crcd_mavg_balind', 'cus_region_move_ind', 'cus_reloan_cap_ind', 'cus_asset_bal', 'crcd_max_quota', 'crcd_lmon_due_amount', 'crcd_due_amount', 'crcd_mavg_balance', 'crcd_points', 'a_mmax_tranbal', 'a_mavg_tranbal', 'b_mmax_tranbal', 'b_mavg_tranbal', 'c_mmax_tranbal', 'c_mavg_tranbal', 'd_mmax_tranbal', 'd_mavg_tranbal', 'e_mmax_tranbal', 'e_mavg_tranbal', 'f_mmax_tranbal', 'f_mavg_tranbal', 'g_mmax_tranbal', 'g_mavg_tranbal', 'h_mmax_tranbal', 'h_mavg_tranbal', 'i_mmax_tranbal', 'i_mavg_tranbal', 'j_mmax_tranbal', 'j_mavg_tranbal', 'k_mmax_tranbal', 'k_mavg_tranbal', 'm_mmax_tranbal', 'm_mavg_tranbal', 'n_mavg_trancount', 'n_mavg_tranbal', 'a_mdivision_tranbal', 'b_mdivision_tranbal', 'c_mdivision_tranbal', 'd_mdivision_tranbal', 'e_mdivision_tranbal', 'f_mdivision_tranbal', 'g_mdivision_tranbal', 'h_mdivision_tranbal', 'i_mdivision_tranbal', 'j_mdivision_tranbal', 'k_mdivision_tranbal', 'm_mdivision_tranbal', 'n_mdivision_tranbal', 'a_div_cus_asset_bal', 'b_div_cus_asset_bal', 'c_div_cus_asset_bal', 'd_div_cus_asset_bal', 'e_div_cus_asset_bal', 'f_div_cus_asset_bal', 'g_div_cus_asset_bal', 'h_div_cus_asset_bal', 'i_div_cus_asset_bal', 'j_div_cus_asset_bal', 'k_div_cus_asset_bal', 'm_div_cus_asset_bal', 'n_div_cus_asset_bal','pass_date1', 'pass_date2', 'interval_mon_count1', 'interval_mon_count2', 'new12', 'new13', 'new14', 'new15', 'new16', 'new17', 'new18', 'new1', 'new2', 'new3', 'new4', 'new5', 'new6', 'new7', 'new8', 'new9', 'new10', 'new11', 'crcd1', 'crcd2', 'crcd3', 'crcd4', 'crcd5', 'interval_date1', 'cus_asset_bal1', 'cus_asset_bal2', 'cus_marr_stat1'\n",
    "        ]\n",
    "cago_feature='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14'\n",
    "feature_train=feature+['target']\n",
    "feature_test=feature\n",
    "dataset_train=dataset_train[feature_train]\n",
    "dataset_test=dataset_test[feature_test]\n",
    "\n",
    "\n",
    "models=[]\n",
    "i=0\n",
    "\n",
    "y_pres=[]\n",
    "y_pres_online=[]\n",
    "index=[]\n",
    "Xs=[]\n",
    "model=Sequential()\n",
    "def cv(dataset_x_ori,dataset_y_ori,k=5,**fit_params) : \n",
    "    global models,i,model,y_pres_online,y_pres,index,Xs\n",
    "    models=[]\n",
    "    dataset_x=dataset_x_ori.values\n",
    "    dataset_y=dataset_y_ori.values\n",
    "    kf = KFold(n_splits=k,random_state=0)\n",
    "    for train_index,test_index in kf.split(dataset_x):\n",
    "        print('!!!!!!!!!!!!!',dataset_train.shape,dataset_test.shape,)\n",
    "        \n",
    "        models=[]\n",
    "        index.append(pd.Series(test_index))\n",
    "        X_train,X_eval = dataset_x[train_index], dataset_x[test_index]\n",
    "        Y_train,Y_eval = dataset_y[train_index], dataset_y[test_index]\n",
    "#         print('1')\n",
    "#         print(dataset_x_ori.iloc[test_index[0],:].values)\n",
    "#         print(X_eval[0,:])\n",
    "#         print('2')\n",
    "#         print(dataset_x_ori.iloc[test_index[-1],:].values)\n",
    "#         print(X_eval[-1,:])\n",
    "        \n",
    "########################################################################    \n",
    "        model = catboost.CatBoostClassifier(iterations=17000,\n",
    "                              depth = 6,\n",
    "                               learning_rate = 0.03,\n",
    "                               custom_loss='AUC',\n",
    "                               eval_metric='AUC',\n",
    "                               bagging_temperature=0.83,\n",
    "                               od_type='Iter',\n",
    "                               rsm = 0.78,\n",
    "                               od_wait=300,\n",
    "                               l2_leaf_reg = 5,\n",
    "                               thread_count = 4,\n",
    "                               random_seed = 967,\n",
    "                               metric_period = 400,\n",
    "                               class_weights=[1,10.2739]  #类别权重\n",
    "                              )\n",
    "########################################################################\n",
    "        \n",
    "        \n",
    "        i=i+1\n",
    "        df=pd.DataFrame(models)\n",
    "        df=df.sort_values([1],ascending=False)\n",
    "        path=df.iat[0,2]\n",
    "        print('load',path)\n",
    "        model=load_model(path)\n",
    "        \n",
    "        y_pr=model.predict(X_eval, verbose=0)\n",
    "        y_pr=pd.DataFrame(y_pr)\n",
    "#         y_pr.index=test_index\n",
    "        y_pres.append(y_pr)\n",
    "        ###########\n",
    "        x=X_eval\n",
    "        x=pd.DataFrame(x)\n",
    "#         x.index=test_index\n",
    "        Xs.append(x)\n",
    "        ###########\n",
    "        y_pr_online=model.predict(dataset_test, verbose=0)\n",
    "        y_pr_online=pd.DataFrame(y_pr_online)\n",
    "        y_pres_online.append(y_pr_online)\n",
    "    \n",
    "    index=pd.concat(index,axis=0)\n",
    "    y_pr=pd.concat(y_pres,axis=0)\n",
    "#     y_pr.index=index\n",
    "#     y_pr=y_pr.sort_index()\n",
    "    y_pr.index=dataset_y_ori.index\n",
    "    #########\n",
    "    X=pd.concat(Xs,axis=0)\n",
    "#     X.index=index\n",
    "#     X=X.sort_index()\n",
    "    X.index=dataset_y_ori.index\n",
    "    X.columns=dataset_x_ori.columns\n",
    "    #########\n",
    "    y_pr_online=pd.concat(y_pres_online,axis=1)\n",
    "    y_pr_online=y_pr_online.mean(axis=1)\n",
    "    print(y_pr_online.shape)\n",
    "    y_pr_online.index=dataset_test.index\n",
    "    return y_pr,y_pr_online,X\n",
    "y_pr,y_pr_online,X=cv(dataset_train_x,dataset_train_y,10)\n",
    "\n",
    "dnn_target=pd.concat([y_pr,y_pr_online])\n",
    "dnn_target.to_csv('dataset/catb_target.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

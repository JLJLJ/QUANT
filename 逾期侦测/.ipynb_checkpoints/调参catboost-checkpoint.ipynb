{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6497238\tbest: 0.6497238 (0)\ttotal: 88.8ms\tremaining: 25m 10s\n",
      "400:\ttest: 0.7149275\tbest: 0.7149275 (400)\ttotal: 34.5s\tremaining: 23m 47s\n",
      "800:\ttest: 0.7190016\tbest: 0.7195361 (737)\ttotal: 1m 9s\tremaining: 23m 15s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.7195361169\n",
      "bestIteration = 737\n",
      "\n",
      "Shrink model to first 738 iterations.\n",
      "0.7195361169316628\n"
     ]
    }
   ],
   "source": [
    "dataset_train=pd.read_hdf('dataset/1_1_3_dnn_target.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_3_dnn_target.h5', key='PREDICT')\n",
    "feature=['crcd_is_overdue', 'cus_sex', 'crcd_is_pc', 'crcd_is_sup', 'cus_type', 'crcd_is_gec', 'crcd_bachange_cnt', 'cus_intvtime_trans',\n",
    "         'cus_edu', 'cus_marr_stat', 'cus_occu', 'cus_oact_pla', 'cus_os_dist', 'crcd_is_gc', 'crcd_bill_mcnt',\n",
    "                 \n",
    "        'cus_age', 'cus_mbank_lcnt', 'cus_active_ind', 'pass_date', 'interval_mon_count', 'interval_date_1stc', 'interval_date_1stc12', 'cus_hisloan_cnt', 'crcd_mavg_balind', 'cus_region_move_ind', 'cus_reloan_cap_ind', 'cus_asset_bal', 'crcd_max_quota', 'crcd_lmon_due_amount', 'crcd_due_amount', 'crcd_mavg_balance', 'crcd_points', 'a_mmax_tranbal', 'a_mavg_tranbal', 'b_mmax_tranbal', 'b_mavg_tranbal', 'c_mmax_tranbal', 'c_mavg_tranbal', 'd_mmax_tranbal', 'd_mavg_tranbal', 'e_mmax_tranbal', 'e_mavg_tranbal', 'f_mmax_tranbal', 'f_mavg_tranbal', 'g_mmax_tranbal', 'g_mavg_tranbal', 'h_mmax_tranbal', 'h_mavg_tranbal', 'i_mmax_tranbal', 'i_mavg_tranbal', 'j_mmax_tranbal', 'j_mavg_tranbal', 'k_mmax_tranbal', 'k_mavg_tranbal', 'm_mmax_tranbal', 'm_mavg_tranbal', 'n_mavg_trancount', 'n_mavg_tranbal', 'a_mdivision_tranbal', 'b_mdivision_tranbal', 'c_mdivision_tranbal', 'd_mdivision_tranbal', 'e_mdivision_tranbal', 'f_mdivision_tranbal', 'g_mdivision_tranbal', 'h_mdivision_tranbal', 'i_mdivision_tranbal', 'j_mdivision_tranbal', 'k_mdivision_tranbal', 'm_mdivision_tranbal', 'n_mdivision_tranbal', 'a_div_cus_asset_bal', 'b_div_cus_asset_bal', 'c_div_cus_asset_bal', 'd_div_cus_asset_bal', 'e_div_cus_asset_bal', 'f_div_cus_asset_bal', 'g_div_cus_asset_bal', 'h_div_cus_asset_bal', 'i_div_cus_asset_bal', 'j_div_cus_asset_bal', 'k_div_cus_asset_bal', 'm_div_cus_asset_bal', 'n_div_cus_asset_bal','pass_date1', 'pass_date2', 'interval_mon_count1', 'interval_mon_count2', 'new12', 'new13', 'new14', 'new15', 'new16', 'new17', 'new18', 'new1', 'new2', 'new3', 'new4', 'new5', 'new6', 'new7', 'new8', 'new9', 'new10', 'new11', 'crcd1', 'crcd2', 'crcd3', 'crcd4', 'crcd5', 'interval_date1', 'cus_asset_bal1', 'cus_asset_bal2', 'cus_marr_stat1'\n",
    "        ]\n",
    "cago_feature=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "cago_feature=[]\n",
    "feature_train=feature+['target']\n",
    "feature_test=feature\n",
    "dataset_train=dataset_train[feature_train]\n",
    "dataset_test=dataset_test[feature_test]\n",
    "seed=None\n",
    "dataset_train_x,dataset_train_y=get_sample(dataset_train[feature_train],target_0=1,target_1=1,seed=seed)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(dataset_train_x,dataset_train_y,test_size=0.2,random_state=seed)\n",
    "\n",
    "params={'iterations':[17000],\n",
    "        'depth':[6],\n",
    "        'learning_rate':[0.01],\n",
    "        'custom_loss':['AUC'],\n",
    "        'eval_metric':['AUC'],\n",
    "        'bagging_temperature':[0.83],  #贝叶斯bootstrap强度设置，default=1\n",
    "        'od_type':['Iter'],  #是否检查过拟合\n",
    "        'rsm':[0.78],\n",
    "        'od_wait':[300],  #达成优化目标以后继续迭代的次数，default=20\n",
    "        'l2_leaf_reg':[5],  #正则化数，default=3.0\n",
    "        'thread_count':[40],\n",
    "        'random_seed':[967],\n",
    "        'leaf_estimation_iterations':[None], #计算叶子节点值时候的迭代次数\n",
    "        'ctr_leaf_count_limit':[None], #类别型特征最大叶子数\n",
    "        'max_ctr_complexity':[4],   #最大特征组合数\n",
    "        'class_weights':[[10.2739,1]],  #类别权重\n",
    "        'random_strength':[1], #树结构确定以后为分裂点进行打分的时候的随机强度，default=1\n",
    "        'min_data_in_leaf':[1], #叶子节点最小样本数，default=1\n",
    "        'max_leaves':[31] #最大叶子数，default=31\n",
    "      }\n",
    "\n",
    "model = catboost.CatBoostClassifier(iterations=17000,\n",
    "                              depth = 6,\n",
    "                               learning_rate = 0.03,\n",
    "                               custom_loss='AUC',\n",
    "                               eval_metric='AUC',\n",
    "                               bagging_temperature=0.83,\n",
    "                               od_type='Iter',\n",
    "                               rsm = 0.78,\n",
    "                               od_wait=150,\n",
    "                               l2_leaf_reg = 5,\n",
    "                               thread_count = 42,\n",
    "                               random_seed = 967,\n",
    "                               metric_period = 400,\n",
    "                               class_weights=[1,10.2739]  #类别权重\n",
    "                              )\n",
    "model.fit(X_train, Y_train, eval_set=(X_test, Y_test),use_best_model=True)\n",
    "pre= model.predict_proba(X_test)[:,1]#.reshape((X_test.shape[0],1))\n",
    "\n",
    "print (roc_auc_score(Y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7247764513905894\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "from functools import wraps\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.externals import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import timedelta\n",
    "from io import StringIO\n",
    "# from sklearn.externals import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from random import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('display.max_columns',None) \n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "\n",
    "dataset_train=pd.read_hdf('dataset/1_1_2_空值填充.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_2_空值填充.h5', key='PREDICT')\n",
    "feature=['crcd_is_overdue', 'cus_sex', 'crcd_is_pc', 'crcd_is_sup', 'cus_type', 'crcd_is_gec', 'crcd_bachange_cnt', 'cus_intvtime_trans',\n",
    "         'cus_edu', 'cus_marr_stat', 'cus_occu', 'cus_oact_pla', 'cus_os_dist', 'crcd_is_gc', 'crcd_bill_mcnt',\n",
    "                 \n",
    "        'cus_age', 'cus_mbank_lcnt', 'cus_active_ind', 'pass_date', 'interval_mon_count', 'interval_date_1stc', 'interval_date_1stc12', 'cus_hisloan_cnt', 'crcd_mavg_balind', 'cus_region_move_ind', 'cus_reloan_cap_ind', 'cus_asset_bal', 'crcd_max_quota', 'crcd_lmon_due_amount', 'crcd_due_amount', 'crcd_mavg_balance', 'crcd_points', 'a_mmax_tranbal', 'a_mavg_tranbal', 'b_mmax_tranbal', 'b_mavg_tranbal', 'c_mmax_tranbal', 'c_mavg_tranbal', 'd_mmax_tranbal', 'd_mavg_tranbal', 'e_mmax_tranbal', 'e_mavg_tranbal', 'f_mmax_tranbal', 'f_mavg_tranbal', 'g_mmax_tranbal', 'g_mavg_tranbal', 'h_mmax_tranbal', 'h_mavg_tranbal', 'i_mmax_tranbal', 'i_mavg_tranbal', 'j_mmax_tranbal', 'j_mavg_tranbal', 'k_mmax_tranbal', 'k_mavg_tranbal', 'm_mmax_tranbal', 'm_mavg_tranbal', 'n_mavg_trancount', 'n_mavg_tranbal', 'a_mdivision_tranbal', 'b_mdivision_tranbal', 'c_mdivision_tranbal', 'd_mdivision_tranbal', 'e_mdivision_tranbal', 'f_mdivision_tranbal', 'g_mdivision_tranbal', 'h_mdivision_tranbal', 'i_mdivision_tranbal', 'j_mdivision_tranbal', 'k_mdivision_tranbal', 'm_mdivision_tranbal', 'n_mdivision_tranbal', 'a_div_cus_asset_bal', 'b_div_cus_asset_bal', 'c_div_cus_asset_bal', 'd_div_cus_asset_bal', 'e_div_cus_asset_bal', 'f_div_cus_asset_bal', 'g_div_cus_asset_bal', 'h_div_cus_asset_bal', 'i_div_cus_asset_bal', 'j_div_cus_asset_bal', 'k_div_cus_asset_bal', 'm_div_cus_asset_bal', 'n_div_cus_asset_bal','pass_date1', 'pass_date2', 'interval_mon_count1', 'interval_mon_count2', 'new12', 'new13', 'new14', 'new15', 'new16', 'new17', 'new18', 'new1', 'new2', 'new3', 'new4', 'new5', 'new6', 'new7', 'new8', 'new9', 'new10', 'new11', 'crcd1', 'crcd2', 'crcd3', 'crcd4', 'crcd5', 'interval_date1', 'cus_asset_bal1', 'cus_asset_bal2', 'cus_marr_stat1'\n",
    "        ]\n",
    "cago_feature='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14'\n",
    "feature_train=feature+['target']\n",
    "feature_test=feature\n",
    "dataset_train=dataset_train[feature_train]\n",
    "dataset_test=dataset_test[feature_test]\n",
    "\n",
    "def get_sample(dataset,target_0=0.33,target_1=0.33,seed=None):\n",
    "    dataset=dataset.copy()\n",
    "    x0=dataset[dataset['target']==0]\n",
    "    x1=dataset[dataset['target']==1]\n",
    "    x0_selected=x0.sample(frac=target_0,random_state=seed)\n",
    "    x1_selected=x1.sample(frac=target_1,random_state=seed)\n",
    "    dataset=pd.concat([x0_selected,x1_selected]).sample(frac=1,random_state=seed)\n",
    "    y_selected=dataset['target']\n",
    "    x_selected=dataset.drop(columns =['target'])\n",
    "    return x_selected,y_selected\n",
    "def cv(dataset_x,dataset_y,model,k=5, **fit_params) : \n",
    "    models=[]\n",
    "    dataset_x=dataset_x.values\n",
    "    dataset_y=dataset_y.values\n",
    "    kf = KFold(n_splits=k,random_state=0)\n",
    "    def run(train_index, test_index,model, **fit_params):\n",
    "        X_train,X_eval = dataset_x[train_index], dataset_x[test_index]\n",
    "        Y_train,Y_eval = dataset_y[train_index], dataset_y[test_index]\n",
    "###########################################################################\n",
    "        model.fit(X_train, Y_train, eval_set=(X_eval, Y_eval),use_best_model=True)\n",
    "\n",
    "        return model,model.best_score_['validation']['AUC']\n",
    "###########################################################################\n",
    "    \n",
    "    re=Parallel(n_jobs=10)(delayed(run)(train_index, test_index,model, **fit_params) for train_index, test_index in kf.split(dataset_x))\n",
    "    models=pd.DataFrame(re)[0].to_list()\n",
    "    avg_score=pd.DataFrame(re)[1].mean()\n",
    "    return models,avg_score\n",
    "\n",
    "def predict(X_test,models):\n",
    "    def run(model):\n",
    "        y_pr=model.predict_proba(X_test)[:,1]\n",
    "        return y_pr\n",
    "    y_pres=Parallel(n_jobs=40)(delayed(run)(model) for model in models)\n",
    "    y_pres=pd.DataFrame(np.array(y_pres).T)\n",
    "    y_pr=y_pres.mean(axis=1)\n",
    "    y_pr.index=X_test.index\n",
    "    return y_pr\n",
    "def add_log(auc,feature,models):\n",
    "    f=open('log.txt','a+')\n",
    "    s=str(auc) +'\\r\\n'+str(feature)+'\\r\\n' +str(models) +'\\r\\n'\n",
    "    f.write(s)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "########################################################################    \n",
    "model = catboost.CatBoostClassifier(iterations=17000,\n",
    "                              depth = 6,\n",
    "                               learning_rate = 0.03,\n",
    "                               custom_loss='AUC',\n",
    "                               eval_metric='AUC',\n",
    "                               bagging_temperature=0.83,\n",
    "                               od_type='Iter',\n",
    "                               rsm = 0.78,\n",
    "                               od_wait=300,\n",
    "                               l2_leaf_reg = 5,\n",
    "                               thread_count = 4,\n",
    "                               random_seed = 967,\n",
    "                               metric_period = 400,\n",
    "                               class_weights=[1,10.2739]  #类别权重\n",
    "                              )\n",
    "########################################################################\n",
    "seed=None\n",
    "dataset_train_x,dataset_train_y=get_sample(dataset_train[feature_train],target_0=1,target_1=1,seed=seed)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(dataset_train_x,dataset_train_y,test_size=0.0001,random_state=seed)\n",
    "cago_feature=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "cago_feature=[]\n",
    "#cago_feature=[]\n",
    "models,avg_score=cv(X_train,Y_train,model,k=10,categorical)\n",
    "print(avg_score)\n",
    "\n",
    "\n",
    "y_pr=predict(dataset_test[feature_test],models)\n",
    "y_pr.to_csv('online/LOAN_JS_FH_SX_04_20191205_01.csv',header=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "待选择参数: dict_keys(['bagging_temperature', 'rsm', 'l2_leaf_reg', 'leaf_estimation_iterations', 'max_ctr_complexity', 'random_strength', 'min_data_in_leaf', 'max_leaves'])\n",
      "0.7236457341909213 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7236457341909213 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 1.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7236457341909213 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 0.83, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7236457341909213 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 0.99, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "最佳评分： 0.7236457341909213 {'iterations': [17000], 'depth': [3], 'learning_rate': [0.005], 'custom_loss': ['AUC'], 'eval_metric': ['AUC'], 'bagging_temperature': [2, 1, 0.83, 0.99], 'od_type': ['Iter'], 'rsm': [0.78], 'od_wait': [1000], 'l2_leaf_reg': [0.1], 'thread_count': [14], 'random_seed': [967], 'leaf_estimation_iterations': [5], 'ctr_leaf_count_limit': [None], 'max_ctr_complexity': [2], 'class_weights': [[1, 10.2739]], 'random_strength': [1], 'min_data_in_leaf': [1], 'max_leaves': [31]} \n",
      "最佳参数： {'iterations': [17000], 'depth': [3], 'learning_rate': [0.005], 'custom_loss': ['AUC'], 'eval_metric': ['AUC'], 'od_type': ['Iter'], 'od_wait': [1000], 'thread_count': [14], 'random_seed': [967], 'ctr_leaf_count_limit': [None], 'class_weights': [[1, 10.2739]], 'bagging_temperature': [2.0]}\n",
      "待选择参数: dict_keys(['rsm', 'l2_leaf_reg', 'leaf_estimation_iterations', 'max_ctr_complexity', 'random_strength', 'min_data_in_leaf', 'max_leaves'])\n",
      "0.7236457341909213 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7235952325053087 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 1.0, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "最佳评分： 0.7236457341909213 {'iterations': [17000], 'depth': [3], 'learning_rate': [0.005], 'custom_loss': ['AUC'], 'eval_metric': ['AUC'], 'bagging_temperature': [2.0], 'od_type': ['Iter'], 'rsm': [0.78, 1], 'od_wait': [1000], 'l2_leaf_reg': [0.1], 'thread_count': [14], 'random_seed': [967], 'leaf_estimation_iterations': [5], 'ctr_leaf_count_limit': [None], 'max_ctr_complexity': [2], 'class_weights': [[1, 10.2739]], 'random_strength': [1], 'min_data_in_leaf': [1], 'max_leaves': [31]} \n",
      "最佳参数： {'iterations': [17000], 'depth': [3], 'learning_rate': [0.005], 'custom_loss': ['AUC'], 'eval_metric': ['AUC'], 'od_type': ['Iter'], 'od_wait': [1000], 'thread_count': [14], 'random_seed': [967], 'ctr_leaf_count_limit': [None], 'class_weights': [[1, 10.2739]], 'bagging_temperature': [2.0], 'rsm': [0.78]}\n",
      "待选择参数: dict_keys(['l2_leaf_reg', 'leaf_estimation_iterations', 'max_ctr_complexity', 'random_strength', 'min_data_in_leaf', 'max_leaves'])\n",
      "0.7236457341909213 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.1, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7237729614503632 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 0.5, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7237464686526138 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 1.0, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7239580312218329 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 2.0, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n",
      "0.7236836466224034 {'iterations': 17000, 'depth': 3, 'learning_rate': 0.005, 'custom_loss': 'AUC', 'eval_metric': 'AUC', 'bagging_temperature': 2.0, 'od_type': 'Iter', 'rsm': 0.78, 'od_wait': 1000, 'l2_leaf_reg': 3.0, 'thread_count': 14, 'random_seed': 967, 'leaf_estimation_iterations': 5, 'ctr_leaf_count_limit': None, 'max_ctr_complexity': 2, 'class_weights': [1, 10.2739], 'random_strength': 1, 'min_data_in_leaf': 1, 'max_leaves': 31}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {EXIT(1)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-827318d20383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'最佳评分：'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\r\\n最佳参数：'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m \u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-827318d20383>\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(params, n_jobs)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mis_selected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_best_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mbest_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-827318d20383>\u001b[0m in \u001b[0;36mget_best_params\u001b[0;34m(params, X_train, X_test, Y_train, Y_test, n_jobs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                               )\n\u001b[1;32m    168\u001b[0m \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcago_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m#y_pr=predict(X_test,models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-827318d20383>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(dataset_x, dataset_y, model, k, n_jobs, **fit_params)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AUC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m###########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mavg_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiang/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiang/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiang/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiang/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiang/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {EXIT(1)}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "from functools import wraps\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.externals import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import timedelta\n",
    "from io import StringIO\n",
    "# from sklearn.externals import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from random import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import catboost\n",
    "\n",
    "dataset_train=pd.read_hdf('dataset/1_1_1_2_dnn_target.h5', key='TRAIN')\n",
    "dataset_test=pd.read_hdf('dataset/1_1_1_2_dnn_target.h5', key='PREDICT')\n",
    "feature=['crcd_is_overdue', 'cus_sex', 'crcd_is_pc', 'crcd_is_sup', 'cus_type', 'crcd_is_gec', 'crcd_bachange_cnt', 'cus_intvtime_trans',\n",
    "         'cus_edu', 'cus_marr_stat', 'cus_occu', 'cus_oact_pla', 'cus_os_dist', 'crcd_is_gc', 'crcd_bill_mcnt',\n",
    "                 \n",
    "        'dnn_target','cus_age', 'cus_mbank_lcnt', 'cus_active_ind', 'pass_date', 'interval_mon_count', 'interval_date_1stc', 'interval_date_1stc12', 'cus_hisloan_cnt', 'crcd_mavg_balind', 'cus_region_move_ind', 'cus_reloan_cap_ind', 'cus_asset_bal', 'crcd_max_quota', 'crcd_lmon_due_amount', 'crcd_due_amount', 'crcd_mavg_balance', 'crcd_points', 'a_mmax_tranbal', 'a_mavg_tranbal', 'b_mmax_tranbal', 'b_mavg_tranbal', 'c_mmax_tranbal', 'c_mavg_tranbal', 'd_mmax_tranbal', 'd_mavg_tranbal', 'e_mmax_tranbal', 'e_mavg_tranbal', 'f_mmax_tranbal', 'f_mavg_tranbal', 'g_mmax_tranbal', 'g_mavg_tranbal', 'h_mmax_tranbal', 'h_mavg_tranbal', 'i_mmax_tranbal', 'i_mavg_tranbal', 'j_mmax_tranbal', 'j_mavg_tranbal', 'k_mmax_tranbal', 'k_mavg_tranbal', 'm_mmax_tranbal', 'm_mavg_tranbal', 'n_mavg_trancount', 'n_mavg_tranbal', 'a_mdivision_tranbal', 'b_mdivision_tranbal', 'c_mdivision_tranbal', 'd_mdivision_tranbal', 'e_mdivision_tranbal', 'f_mdivision_tranbal', 'g_mdivision_tranbal', 'h_mdivision_tranbal', 'i_mdivision_tranbal', 'j_mdivision_tranbal', 'k_mdivision_tranbal', 'm_mdivision_tranbal', 'n_mdivision_tranbal', 'a_div_cus_asset_bal', 'b_div_cus_asset_bal', 'c_div_cus_asset_bal', 'd_div_cus_asset_bal', 'e_div_cus_asset_bal', 'f_div_cus_asset_bal', 'g_div_cus_asset_bal', 'h_div_cus_asset_bal', 'i_div_cus_asset_bal', 'j_div_cus_asset_bal', 'k_div_cus_asset_bal', 'm_div_cus_asset_bal', 'n_div_cus_asset_bal','pass_date1', 'pass_date2', 'interval_mon_count1', 'interval_mon_count2', 'new12', 'new13', 'new14', 'new15', 'new16', 'new17', 'new18', 'new1', 'new2', 'new3', 'new4', 'new5', 'new6', 'new7', 'new8', 'new9', 'new10', 'new11', 'crcd1', 'crcd2', 'crcd3', 'crcd4', 'crcd5', 'interval_date1', 'cus_asset_bal1', 'cus_asset_bal2', 'cus_marr_stat1'\n",
    "        ]\n",
    "cago_feature=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "thread=3\n",
    "boost_thread=14\n",
    "params={'iterations':[17000],\n",
    "        'depth':[3],  ###\n",
    "        'learning_rate':[0.005],\n",
    "        'custom_loss':['AUC'],\n",
    "        'eval_metric':['AUC'],\n",
    "        'bagging_temperature':[2,1,0.83,0.99],  #贝叶斯bootstrap强度设置，default=1\n",
    "        'od_type':['Iter'],  #是否检查过拟合\n",
    "        'rsm':[0.78,1],\n",
    "        'od_wait':[1000],  #达成优化目标以后继续迭代的次数，default=20\n",
    "        'l2_leaf_reg':[0.1,0.5,1,2,3,5],  #正则化数，default=3.0\n",
    "        'thread_count':[boost_thread],\n",
    "        'random_seed':[967],\n",
    "        'leaf_estimation_iterations':[5,18,22,30], #计算叶子节点值时候的迭代次数\n",
    "        'ctr_leaf_count_limit':[None], #类别型特征最大叶子数\n",
    "        'max_ctr_complexity':[2,4,8,12],   #最大特征组合数\n",
    "        'class_weights':[[1,10.2739]],  #类别权重\n",
    "        'random_strength':[1,2,5], #树结构确定以后为分裂点进行打分的时候的随机强度，default=1\n",
    "        'min_data_in_leaf':[1,0.1,0.01], #叶子节点最小样本数，default=1\n",
    "        'max_leaves':[31,16,8,64] #最大叶子数，default=31\n",
    "      }\n",
    "\n",
    "pd.set_option('display.max_columns',None) \n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "\n",
    "\n",
    "#调参类定义，传入多个参数组成的一个字典，返回一个迭代器，感觉比sklearn中的调参函数好用，个人习惯吧\n",
    "class params_iter:\n",
    "    def getPlans(self,lis,jude=True):\n",
    "        if jude: \n",
    "            lis = [[[i] for i in lis[0]]] + lis[1:]\n",
    "        if len(lis) > 2:\n",
    "            for i in lis[0]:\n",
    "                for j in lis[1]:\n",
    "                    self.getPlans([[i + [j]]] + lis[2:], False)\n",
    "        elif len(lis) == 2:\n",
    "            for i in lis[0]:\n",
    "                for j in lis[1]:\n",
    "                    self.param_list.append(i + [j])\n",
    "                \n",
    "    def __init__(self,params):\n",
    "        self.params=params\n",
    "        self.cur_index=0\n",
    "        self.param_list=[]\n",
    "        val=list(params.values())\n",
    "        keys=list(params.keys())\n",
    "        self.getPlans(val)\n",
    "        self.df=pd.DataFrame(self.param_list,columns=keys)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        if self.df.shape[0]==self.cur_index:\n",
    "            raise StopIteration\n",
    "        x = self.df.iloc[self.cur_index,:]\n",
    "        self.cur_index += 1\n",
    "        return x.to_dict()\n",
    "    \n",
    "def get_sample(dataset,target_0=0.33,target_1=0.33,seed=None):\n",
    "    dataset=dataset.copy()\n",
    "    x0=dataset[dataset['target']==0]\n",
    "    x1=dataset[dataset['target']==1]\n",
    "    x0_selected=x0.sample(frac=target_0,random_state=seed)\n",
    "    x1_selected=x1.sample(frac=target_1,random_state=seed)\n",
    "    dataset=pd.concat([x0_selected,x1_selected]).sample(frac=1,random_state=seed)\n",
    "    y_selected=dataset['target']\n",
    "    x_selected=dataset.drop(columns =['target'])\n",
    "    return x_selected,y_selected\n",
    "def cv(dataset_x,dataset_y,model,k=5,n_jobs=3,**fit_params) : \n",
    "    models=[]\n",
    "    dataset_x=dataset_x.values\n",
    "    dataset_y=dataset_y.values\n",
    "    kf = KFold(n_splits=k,random_state=0)\n",
    "    def run(train_index, test_index,model, **fit_params):\n",
    "        X_train,X_eval = dataset_x[train_index], dataset_x[test_index]\n",
    "        Y_train,Y_eval = dataset_y[train_index], dataset_y[test_index]\n",
    "###########################################################################\n",
    "        model.fit(X_train, Y_train, eval_set=(X_eval, Y_eval),use_best_model=True)\n",
    "\n",
    "        return model,model.best_score_['validation']['AUC']\n",
    "###########################################################################\n",
    "    re=Parallel(n_jobs=n_jobs)(delayed(run)(train_index, test_index,model, **fit_params) for train_index, test_index in kf.split(dataset_x))\n",
    "    models=pd.DataFrame(re)[0].to_list()\n",
    "    avg_score=pd.DataFrame(re)[1].mean()\n",
    "    return models,avg_score\n",
    "\n",
    "def predict(X_test,models):\n",
    "    def run(model):\n",
    "        y_pr=model.predict_proba(X_test)[:,1]\n",
    "        return y_pr\n",
    "    y_pres=Parallel(n_jobs=40)(delayed(run)(model) for model in models)\n",
    "    y_pres=pd.DataFrame(np.array(y_pres).T)\n",
    "    y_pr=y_pres.mean(axis=1)\n",
    "    y_pr.index=X_test.index\n",
    "    return y_pr\n",
    "\n",
    "feature_train=feature+['target']\n",
    "feature_test=feature\n",
    "dataset_train=dataset_train[feature_train]\n",
    "dataset_test=dataset_test[feature_test]\n",
    "\n",
    "def get_best_params(params,X_train,X_test,Y_train,Y_test,n_jobs=3):\n",
    "    '''\n",
    "    params只会有一个key有多个参数，使用params_iter逐个抽取评分，返回最高评分和参数\n",
    "    \n",
    "    '''\n",
    "    li=[]\n",
    "    for i,param in enumerate(params_iter(params)):\n",
    "#         print(param)\n",
    "########################################################################    \n",
    "        model = catboost.CatBoostClassifier(iterations=param['iterations'],\n",
    "                            depth=param['depth'],\n",
    "                            learning_rate=param['learning_rate'],\n",
    "                            custom_loss=param['custom_loss'],\n",
    "                            eval_metric=param['eval_metric'],\n",
    "                            bagging_temperature=param['bagging_temperature'],\n",
    "                            od_type=param['od_type'],\n",
    "                            rsm=param['rsm'],\n",
    "                            od_wait=param['od_wait'],\n",
    "                            l2_leaf_reg=param['l2_leaf_reg'],\n",
    "                            thread_count=param['thread_count'],\n",
    "                            random_seed=param['random_seed'],\n",
    "                            leaf_estimation_iterations=param['leaf_estimation_iterations'],\n",
    "                            ctr_leaf_count_limit=param['ctr_leaf_count_limit'],\n",
    "                            max_ctr_complexity=param['max_ctr_complexity'],\n",
    "                            class_weights=param['class_weights'],\n",
    "                            random_strength=param['random_strength'],\n",
    "                            min_data_in_leaf=param['min_data_in_leaf'],\n",
    "                            max_leaves=param['max_leaves']                  \n",
    "                              )\n",
    "########################################################################\n",
    "        models,avg_score=cv(X_train,Y_train,model,k=3,n_jobs=n_jobs, categorical_feature=cago_feature)\n",
    "########################################################################\n",
    "        #y_pr=predict(X_test,models)\n",
    "        #offline_test_auc=roc_auc_score(Y_test,y_pr)\n",
    "        print(avg_score,param)\n",
    "        #add_log(avg_score,feature_train,models)\n",
    "        li.append((avg_score,param))\n",
    "    df=pd.DataFrame(li)\n",
    "    score=df[0].sort_values(ascending=False).values[0]#######################################\n",
    "    for i in range(len(li)):\n",
    "        if score==li[i][0]:\n",
    "            p=li[i][1]\n",
    "            break\n",
    "    return score,p\n",
    "def greedy(params,n_jobs=3):\n",
    "    seed=None\n",
    "    dataset_train_x,dataset_train_y=get_sample(dataset_train[feature_train],target_0=1,target_1=1,seed=seed)\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(dataset_train_x,dataset_train_y,test_size=0.001,random_state=seed)\n",
    "    best_value={}\n",
    "    params_copy=params.copy()\n",
    "    while(True):\n",
    "        \n",
    "        is_selected=False\n",
    "        keys=params.keys()\n",
    "        for key in list(keys):\n",
    "            if len(params[key])==1:\n",
    "                best_value[key]=params[key]\n",
    "                del params[key]\n",
    "        if len(params)==0:\n",
    "            break\n",
    "        print('待选择参数:',params.keys())\n",
    "        for best_value_key in best_value.keys():\n",
    "            params_copy[best_value_key]=best_value[best_value_key]\n",
    "        keys=list(params.keys())\n",
    "        for key in keys:\n",
    "            if is_selected:\n",
    "                params_copy[key]=[params[key][0]]\n",
    "            else:\n",
    "                cur_key=key\n",
    "                params_copy[key]=params[key]\n",
    "                del params[key]\n",
    "                is_selected=True\n",
    "        ############################\n",
    "        score,param=get_best_params(params_copy,X_train,X_test,Y_train,Y_test)\n",
    "        ############################\n",
    "        best_value[cur_key]=[param[cur_key]]\n",
    "        if not is_selected:\n",
    "            break\n",
    "        print('最佳评分：',score,params_copy,'\\r\\n最佳参数：',best_value)\n",
    "\n",
    "greedy(params,n_jobs=thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=pd.Series(range(5))\n",
    "s.sort_values(ascending=False).values[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
